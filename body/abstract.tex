%\begin{abstract}
%	Word alignment is an important task.
%	Encounter noisyness.
%	We propose a novel method to mitigate the noisyness.
%	We varify effectiveness of our approach.
%\end{abstract}

\begin{abstract}
In this paper,
	we propose novel word alignment methods in unsupervised-method manner.
\cmnt{write catchy one sentence}
\end{abstract}

\begin{comment}
\cmnt{Messy explanation. Clarify our }
Cross-lingual correspondence has a pivotal position in NLP tasks, 
	such as machine translation. 
As a fundamental research, 
	unsupervised methods of high quality multilingual alignment have been widely studied. 
In previous works, 
	the pre-trained word embeddings are generally used as the condition of alignment.
Considering the nonnegligible impact on disparate quality of word embeddings, 
	several methods have tried to avoid the influence given by low frequency words.
However, 
	they only consider the noise in monolingual word embeddings and pay no mind on abnormality caused by bilingual alignment. 
To solve these problems, 
	we develop a novel method that can accustom the weight of word automatically and show our method achieves better performance than state-of-art unsupervised model. 
The learned weights of words also demonstrate that the frequency is not the only producer of noise in bilingual alignment. 
Meanwhile, 
	our model has high robustness on different language pairs and alignment settings.
\end{comment}
